# Railway Environment Variables for Synapse
# Copy these to your Railway project environment variables

# Core Configuration
PORT=8000
HOST=0.0.0.0
CORS_ORIGINS=*

# LLM Configuration (External Service Required)
LLAMA_URL=https://your-llm-service.com/v1/chat/completions
LLAMA_MODEL=qwen2.5-3b-instruct-q4_k_m

# Alternative: OpenAI API
# LLAMA_URL=https://api.openai.com/v1/chat/completions
# OPENAI_API_KEY=your_openai_api_key

# Alternative: Anthropic Claude
# LLAMA_URL=https://api.anthropic.com/v1/messages
# ANTHROPIC_API_KEY=your_anthropic_api_key

# Embedding Model
EMB_MODEL=BAAI/bge-base-en-v1.5

# Context Size
CTX_SIZE=32768

# Guardian Configuration
GUARDIAN_ENABLED=false

# Vector Database (Optional - for RAG features)
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=synapse-kb

# Alternative: Weaviate
# WEAVIATE_URL=https://your-weaviate-instance.com
# WEAVIATE_API_KEY=your_weaviate_key

# File Storage (Optional - for document uploads)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_BUCKET_NAME=synapse-documents
AWS_REGION=us-west-2

# Alternative: Google Cloud Storage
# GOOGLE_CLOUD_PROJECT=your_project_id
# GOOGLE_CLOUD_BUCKET=synapse-documents

# Note: Railway provides persistent storage, so local file operations will work!
# No need for external storage unless you want redundancy or sharing.
